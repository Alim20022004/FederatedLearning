{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alim20022004/FederatedLearning/blob/main/FEDlearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GW7YKNXXckc",
        "outputId": "60d2c4f2-8fd5-45b4-f50b-5e7cea45254f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m130.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.0/540.0 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyopenssl 24.2.1 requires cryptography<44,>=41.0.5, but you have cryptography 44.0.3 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install medmnist\n",
        "!pip -q install flwr[simulation]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vucMMFXsW2sh",
        "outputId": "2fbaa90a-7008-44ff-efc8-33387537c9ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flower 1.18.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "from medmnist import PathMNIST\n",
        "import flwr as fl\n",
        "from typing import Dict, List, Tuple\n",
        "from flwr.common import Context, Metrics\n",
        "from flwr.common import (\n",
        "    Code,\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    GetParametersIns,\n",
        "    GetParametersRes,\n",
        "    Status,\n",
        "    ndarrays_to_parameters,\n",
        "    parameters_to_ndarrays,\n",
        ")\n",
        "from flwr.client import Client, ClientApp, NumPyClient\n",
        "from flwr.common import log\n",
        "from flwr.common import Scalar,NDArrays\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.simulation import run_simulation\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Flower {fl.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbIu8qxeW2sm"
      },
      "source": [
        "# `1.Define THE  MODEL`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IMfyuz0hQ2G",
        "outputId": "86e44bc5-e4e1-4de5-d3bb-247cd5bfd3ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 187MB/s]\n"
          ]
        }
      ],
      "source": [
        "num_classes = 9\n",
        "w=EfficientNet_B0_Weights.IMAGENET1K_V1\n",
        "modeleff = efficientnet_b0(weights=w)\n",
        "modeleff.classifier[1] = nn.Linear(modeleff.classifier[1].in_features, num_classes)\n",
        "modelefficient=modeleff.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14EwdTljW2so"
      },
      "source": [
        "# `2.Traning & validation Function`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdM5aFj1W2sp"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_epoch(model, train_loader):\n",
        "    \"\"\"Train model for one epoch.\"\"\"\n",
        "    model.train()#train model\n",
        "    correct, total, running_loss = 0,0,0.0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.squeeze().to(device)\n",
        "        optimizer.zero_grad() # Clear gradients\n",
        "        outputs = model(inputs)# Forward pass\n",
        "        loss = criterion(outputs, labels)# Compute loss\n",
        "        loss.backward() # Backward pass (compute gradients)\n",
        "        optimizer.step()# Update weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = 100 * correct / total\n",
        "    return train_loss, train_acc\n",
        "\n",
        "\n",
        "def validate(model, val_loader):\n",
        "    \"\"\"Validate model on validation set.\"\"\"\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "    correct, total, val_loss = 0,0,0.0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.squeeze().to(device)\n",
        "            outputs = model(inputs)  # Forward pass\n",
        "            loss = criterion(outputs, labels)# Compute loss\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1) # Get predicted class\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    val_loss = val_loss / len(val_loader)\n",
        "    val_acc = 100 * correct / total\n",
        "    return val_loss, val_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF6w805DW2ss"
      },
      "source": [
        "# `3.Evaluation THE Model`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdPGwJoTW2ss"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    \"\"\"Evaluate model on test set and return predictions/labels.\"\"\"\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    test_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device),labels.squeeze().to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            total += labels.size(0)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "\n",
        "    test_loss = test_loss / len(test_loader)\n",
        "    test_acc = 100 * correct / total\n",
        "    return test_loss,test_acc,np.array(all_preds), np.array(all_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qidxs4MrW2st"
      },
      "source": [
        "# `4.Lead THE DATASET`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzqViSBsW2su"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "NUM_CLIENTS = 5\n",
        "BATCH_SIZE = 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWVsE3D0-GnQ"
      },
      "outputs": [],
      "source": [
        "def load_full_datasets():\n",
        "    \"\"\"\n",
        "    Load the complete PathMNIST dataset splits with appropriate transformations.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_dataset, val_dataset, test_dataset)\n",
        "    \"\"\"\n",
        "    # Transformations for training data (with augmentation)\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    # Transformations for validation and testing (without augmentation)\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    # Load the full datasets\n",
        "    train_dataset = PathMNIST(split='train', transform=train_transform, download=True)\n",
        "    val_dataset = PathMNIST(split='val', transform=test_transform, download=True)\n",
        "    return train_dataset, val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unU0q7XgI2jE"
      },
      "outputs": [],
      "source": [
        "def load_test_dataset():\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "    test_dataset = PathMNIST(split='test', transform=test_transform, download=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "    return test_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0i8lEaTM8eJ"
      },
      "outputs": [],
      "source": [
        "def partition_dataset(dataset, num_partitions: int):\n",
        "    # Shuffle dataset indices randomly\n",
        "    indices = np.random.permutation(len(dataset))\n",
        "    # Split indices into num_partitions parts\n",
        "    partitions_indices = np.array_split(indices, num_partitions)\n",
        "    # Create a Subset for each partition\n",
        "    subsets = [Subset(dataset, idx) for idx in partitions_indices]\n",
        "    return subsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TrHy6Rf1a1-",
        "outputId": "35c024f1-fbd4-43e4-c9a1-01b2ceca8099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and partitioning datasets globally...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 206M/206M [00:11<00:00, 18.1MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full train dataset size: 89996\n",
            "Full val dataset size: 10004\n",
            "Train partitions: 5\n",
            "Val partitions: 5\n",
            "Data loaded and partitioned for 5 clients in 15.00 seconds.\n"
          ]
        }
      ],
      "source": [
        "# --- Perform data loading and partitioning ONCE globally ---\n",
        "print(\"Loading and partitioning datasets globally...\")\n",
        "start_time_data_prep = time.time()\n",
        "\n",
        "# 1. Load full datasets once\n",
        "FULL_TRAIN_DATASET, FULL_VAL_DATASET = load_full_datasets()\n",
        "print(f\"Full train dataset size: {len(FULL_TRAIN_DATASET)}\")\n",
        "print(f\"Full val dataset size: {len(FULL_VAL_DATASET)}\")\n",
        "# 2. Partition them once\n",
        "# Choose your partitioning strategy (e.g., Non-IID)\n",
        "TRAIN_PARTITIONS = partition_dataset(FULL_TRAIN_DATASET, NUM_CLIENTS)\n",
        "print(f\"Train partitions: {len(TRAIN_PARTITIONS)}\")\n",
        "\n",
        "VAL_PARTITIONS = partition_dataset(FULL_VAL_DATASET, NUM_CLIENTS)\n",
        "print(f\"Val partitions: {len(VAL_PARTITIONS)}\")\n",
        "# Or for IID:\n",
        "# TRAIN_PARTITIONS = partition_dataset(FULL_TRAIN_DATASET, NUM_CLIENTS)\n",
        "# VAL_PARTITIONS = partition_dataset(FULL_VAL_DATASET, NUM_CLIENTS)\n",
        "\n",
        "end_time_data_prep = time.time()\n",
        "print(f\"Data loaded and partitioned for {NUM_CLIENTS} clients in {end_time_data_prep - start_time_data_prep:.2f} seconds.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LMnGIvC7cpZ",
        "outputId": "665cf90b-1e71-44a7-aa83-6ce9467f44d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataset.Subset object at 0x7999e52dfd50>\n",
            "<torch.utils.data.dataset.Subset object at 0x7999e52fef90>\n"
          ]
        }
      ],
      "source": [
        "print(TRAIN_PARTITIONS[0])\n",
        "print(VAL_PARTITIONS[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "54i_Pe-I8IUL",
        "outputId": "e56c4626-1af8-4b2d-ba1d-dd7803da0aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Visualizing data distribution for 5 clients...\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2000x400 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np # Ensure numpy is imported\n",
        "\n",
        "# Assume these global variables are defined and populated as in your main script:\n",
        "# NUM_CLIENTS\n",
        "# FULL_TRAIN_DATASET\n",
        "# TRAIN_PARTITIONS\n",
        "# num_classes\n",
        "\n",
        "def visualize_client_data_distribution(): # Using global variables as per previous structure\n",
        "    \"\"\"\n",
        "    Visualize the distribution of dataset categories for each client.\n",
        "    Adapts layout for NUM_CLIENTS = 5 or NUM_CLIENTS = 10.\n",
        "    Uses global variables NUM_CLIENTS, FULL_TRAIN_DATASET, TRAIN_PARTITIONS, num_classes.\n",
        "    \"\"\"\n",
        "    global NUM_CLIENTS, FULL_TRAIN_DATASET, TRAIN_PARTITIONS, num_classes # Explicitly declare usage of globals\n",
        "\n",
        "    print(f\"Visualizing data distribution for {NUM_CLIENTS} clients...\")\n",
        "\n",
        "    if NUM_CLIENTS == 5:\n",
        "        nrows = 1\n",
        "        ncols = 5\n",
        "        figsize = (20, 4)\n",
        "    elif NUM_CLIENTS == 10:\n",
        "        nrows = 2\n",
        "        ncols = 5\n",
        "        figsize = (20, 8) # (width, height)\n",
        "    elif NUM_CLIENTS == 1:\n",
        "        nrows = 1\n",
        "        ncols = 1\n",
        "        figsize = (5, 4)\n",
        "    else:\n",
        "        # Default layout for other numbers of clients (as in previous version)\n",
        "        # This part handles cases other than 1, 5, or 10\n",
        "        ncols_default = min(NUM_CLIENTS, 5) # Max 5 columns, or fewer if fewer clients\n",
        "        nrows_default = (NUM_CLIENTS + ncols_default - 1) // ncols_default\n",
        "        figsize = (min(20, ncols_default * 4), nrows_default * 4)\n",
        "        nrows, ncols = nrows_default, ncols_default # Assign to nrows, ncols for consistency\n",
        "        print(f\"Using default layout: {nrows} rows, {ncols} columns for {NUM_CLIENTS} clients.\")\n",
        "\n",
        "\n",
        "    # squeeze=False ensures axs is always 2D, making .flatten() safe\n",
        "    fig, axs_grid = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, squeeze=False)\n",
        "    axs = axs_grid.flatten() # Flatten to iterate easily\n",
        "\n",
        "    for i in range(NUM_CLIENTS):\n",
        "        if i >= len(axs): # Should not happen if nrows, ncols are calculated correctly\n",
        "            print(f\"Warning: Not enough subplots for client {i}. Skipping.\")\n",
        "            break\n",
        "        ax = axs[i] # Current subplot\n",
        "\n",
        "        subset_indices = TRAIN_PARTITIONS[i].indices\n",
        "\n",
        "        labels = []\n",
        "        for idx in subset_indices:\n",
        "            # Accessing labels (assuming PathMNIST structure or similar)\n",
        "            # dataset[idx] gives (image, label_tensor)\n",
        "            # label_tensor.item() gives the Python number\n",
        "            label_val = FULL_TRAIN_DATASET.targets[idx] if hasattr(FULL_TRAIN_DATASET, 'targets') else FULL_TRAIN_DATASET[idx][1]\n",
        "            if hasattr(label_val, 'item'):\n",
        "                label_val = label_val.item()\n",
        "            labels.append(int(label_val))\n",
        "\n",
        "        counts = [labels.count(cls) for cls in range(num_classes)]\n",
        "\n",
        "        sns.barplot(\n",
        "            x=list(range(num_classes)),\n",
        "            y=counts,\n",
        "            hue=list(range(num_classes)), # Not strictly necessary if x defines the groups\n",
        "            ax=ax,\n",
        "            palette=\"viridis\",\n",
        "            legend=False # No legend if hue is not used distinctively\n",
        "        )\n",
        "        ax.set_title(f'Client {i}')\n",
        "        ax.set_xlabel('Class')\n",
        "\n",
        "        # Only show Y-axis label for the first plot in each row\n",
        "        if i % ncols == 0:\n",
        "            ax.set_ylabel('Count')\n",
        "        else:\n",
        "            ax.set_ylabel('') # Clear y-label for other plots in the row\n",
        "\n",
        "    # Hide any unused subplots if NUM_CLIENTS is not a perfect multiple of ncols\n",
        "    for j in range(NUM_CLIENTS, nrows * ncols):\n",
        "        if j < len(axs): # Check index bounds\n",
        "            fig.delaxes(axs[j])\n",
        "\n",
        "    plt.suptitle(f'Data Distribution for {NUM_CLIENTS} Clients (IID)', fontsize=16)\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to make space for suptitle\n",
        "    plt.show()\n",
        "visualize_client_data_distribution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jUPz6KSj3TE0"
      },
      "outputs": [],
      "source": [
        "def load_client_dataloaders(partition_id: int):\n",
        "    \"\"\"\n",
        "    Creates DataLoaders for a specific client using pre-partitioned global data.\n",
        "    \"\"\"\n",
        "    if not (0 <= partition_id < NUM_CLIENTS):\n",
        "        raise ValueError(f\"Partition ID {partition_id} is out of bounds for {NUM_CLIENTS} clients.\")\n",
        "\n",
        "    client_train_subset = TRAIN_PARTITIONS[partition_id]\n",
        "    client_val_subset = VAL_PARTITIONS[partition_id]\n",
        "\n",
        "    train_loader = DataLoader(client_train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True if device.type == \"cuda\" else False)\n",
        "    val_loader = DataLoader(client_val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True if device.type == \"cuda\" else False)\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdZVXCzTW2sw"
      },
      "source": [
        "# 6.Federated Learning With FLOWER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ROn5GyNQW2sw"
      },
      "outputs": [],
      "source": [
        "def get_parameters(model) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(model, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(model.state_dict().keys(), parameters) # k ,v\n",
        "    state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "    model.load_state_dict(state_dict)#updated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBnjyGmOW2sx"
      },
      "source": [
        "### 6.1. Define the Flower ClientApp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A-AIb1rAW2sx"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(NumPyClient):\n",
        "    def __init__(self,partition_id,model, train_loader, val_loader):\n",
        "        self.partition_id = partition_id\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "\n",
        "\n",
        "    def get_parameters(self, config) :\n",
        "        #get the model parameters and return them as a list of NumPy ndarray’s\n",
        "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
        "        return get_parameters(self.model)\n",
        "\n",
        "    def fit(self, parameters: List[np.ndarray], config: Dict) -> Tuple[List[np.ndarray], int, Dict]:\n",
        "        print(f\"[Client {self.partition_id}] fit\")\n",
        "        train_start_time = time.time()\n",
        "        set_parameters(self.model, parameters)\n",
        "        # Start timing the training process\n",
        "        train_loss, train_acc = train_epoch(self.model, self.train_loader)\n",
        "        # End timing the training process\n",
        "        train_end_time = time.time()\n",
        "        train_duration = train_end_time - train_start_time\n",
        "        print(f\"Client training duration {train_duration}\")\n",
        "        return self.get_parameters({}), len(self.train_loader),{\"train_duration\": train_duration}\n",
        "\n",
        "    def evaluate(self, parameters: List[np.ndarray], config: Dict) -> Tuple[float, int, Dict]:\n",
        "        print(f\"[Client {self.partition_id}] evaluate\")\n",
        "        set_parameters(self.model, parameters)\n",
        "        val_loss, val_acc = validate(self.model, self.val_loader)\n",
        "        return float(val_loss), len(self.val_loader), {\"val_acc\": float(val_acc)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mlEbksUf3JK_"
      },
      "outputs": [],
      "source": [
        "class FlowerClientcustom(Client):\n",
        "    def __init__(self, partition_id, model, train_loader, val_loader):\n",
        "        self.partition_id = partition_id\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "\n",
        "    def get_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n",
        "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
        "\n",
        "        # Get parameters as a list of NumPy ndarray's\n",
        "        ndarrays: List[np.ndarray] = get_parameters(self.model)\n",
        "\n",
        "        # Serialize ndarray's into a Parameters object\n",
        "        parameters = ndarrays_to_parameters(ndarrays)\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return GetParametersRes(\n",
        "            status=status,\n",
        "            parameters=parameters,\n",
        "        )\n",
        "\n",
        "    def fit(self, ins: FitIns) -> FitRes:\n",
        "        print(f\"[Client {self.partition_id}] fit\")\n",
        "        train_start_time = time.time()\n",
        "        # Deserialize parameters to NumPy ndarray's\n",
        "        parameters_original = ins.parameters\n",
        "        ndarrays_original = parameters_to_ndarrays(parameters_original)\n",
        "\n",
        "        # Update local model, train, get updated parameters\n",
        "        set_parameters(self.model, ndarrays_original)\n",
        "        train_loss, train_acc = train_epoch(self.model, self.train_loader)\n",
        "        print(f\"Train accuracy : {train_acc}| Train loss :{train_loss}\")\n",
        "        ndarrays_updated = get_parameters(self.model)\n",
        "\n",
        "        # Serialize ndarray's into a Parameters object\n",
        "        parameters_updated = ndarrays_to_parameters(ndarrays_updated)\n",
        "        train_end_time = time.time()\n",
        "        train_duration = train_end_time - train_start_time\n",
        "        print(f\"Client training duration {train_duration}\")\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return FitRes(\n",
        "            status=status,\n",
        "            parameters=parameters_updated,\n",
        "            num_examples=len(self.train_loader),\n",
        "            metrics={\"train_duration\": train_duration},\n",
        "        )\n",
        "\n",
        "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
        "        print(f\"[Client {self.partition_id}] evaluate\")\n",
        "        # Deserialize parameters to NumPy ndarray's\n",
        "        parameters_original = ins.parameters\n",
        "        ndarrays_original = parameters_to_ndarrays(parameters_original)\n",
        "        set_parameters(self.model, ndarrays_original)\n",
        "        val_loss, val_acc = validate(self.model, self.val_loader)\n",
        "        print(f\"Val accuracy : {val_acc}| val loss :{val_loss}\")\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return EvaluateRes(\n",
        "            status=status,\n",
        "            loss=float(val_loss),\n",
        "            num_examples=len(self.val_loader),\n",
        "            metrics={\"val_acc\": float(val_acc)},\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OyPGpUTFW2sx"
      },
      "outputs": [],
      "source": [
        "def client_fn(context: Context) ->Client:\n",
        "    \"\"\"Create Flower client with partition ID.\"\"\"\n",
        "    model=modelefficient\n",
        "    partition_id = context.node_config[\"partition-id\"]\n",
        "    train_loader, val_loader =load_client_dataloaders(partition_id)\n",
        "    print(f\"Client {partition_id} initialized. Train samples: {len(train_loader.dataset)}, Val samples: {len(val_loader.dataset)}\")\n",
        "    return FlowerClientcustom(partition_id,model,train_loader, val_loader).to_client()\n",
        "\n",
        "client_app = ClientApp(client_fn=client_fn)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH8aCrK5W2sy"
      },
      "source": [
        "### 6.2 function Aggregation validation/test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jO9f7QlHW2sy"
      },
      "outputs": [],
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "   # Aggregate validation accuracy\n",
        "    val_accs = [num_examples * m[\"val_acc\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "    return {\"val_acc\": sum(val_accs) / sum(examples)}\n",
        "\n",
        "def simple_avg_training_time(metrics):\n",
        "    avg_time = sum(m[\"train_duration\"] for _, m in metrics) / len(metrics)\n",
        "    return {\"avg_training_time\": avg_time}\n",
        "\n",
        "test_loader = load_test_dataset()\n",
        "def evaluate_fn(\n",
        "        server_round: int, parameters: NDArrays, config: Dict[str,Scalar],\n",
        "    ) -> Tuple[float, Dict[str, Scalar]]:\n",
        "        model = modelefficient\n",
        "        set_parameters(model, parameters)\n",
        "        test_loss, test_acc, _, _ = evaluate_model(model, test_loader)\n",
        "        print(f\"Global Test Accuracy (Round {server_round}): {test_acc:.2f}%\")\n",
        "        return test_loss, {\"test_acc\": test_acc }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTGVw51mW2sz"
      },
      "source": [
        "### 6.4. Define the Flower ServertApp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-xps3TfYW2sz"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create an instance of the model and get the parameters\n",
        "params =get_parameters(modeleff)\n",
        "# Global variables for timing data\n",
        "round_times = []\n",
        "aggregation_times = []\n",
        "\n",
        "def server_fn(context: Context) -> ServerAppComponents:\n",
        "    global round_times, aggregation_times\n",
        "    # Reset timing data for each simulation\n",
        "    round_times = []\n",
        "    aggregation_times = []\n",
        "\n",
        "    class CustomFedAvg(FedAvg):\n",
        "        def configure_fit(self, server_round, parameters, client_manager):\n",
        "            global round_times, aggregation_times\n",
        "            self.round_start_time = time.time()\n",
        "            return super().configure_fit(server_round, parameters, client_manager)\n",
        "\n",
        "        def aggregate_fit(self, server_round, results, failures):\n",
        "            global round_times, aggregation_times\n",
        "            agg_start = time.time()\n",
        "            aggregated = super().aggregate_fit(server_round, results, failures)\n",
        "            agg_duration = time.time() - agg_start\n",
        "\n",
        "            if not failures:\n",
        "                aggregation_times.append((server_round, agg_duration))\n",
        "                round_times.append((server_round, time.time() - self.round_start_time))\n",
        "            return aggregated\n",
        "\n",
        "    strategy = CustomFedAvg(\n",
        "        fraction_fit=1,\n",
        "        fraction_evaluate=0,\n",
        "        min_available_clients=NUM_CLIENTS,\n",
        "        fit_metrics_aggregation_fn=simple_avg_training_time,\n",
        "        evaluate_fn=evaluate_fn,\n",
        "        initial_parameters=ndarrays_to_parameters(params),\n",
        "        #evaluate_metrics_aggregation_fn=weighted_average,\n",
        "    )\n",
        "\n",
        "    config = ServerConfig(num_rounds=10)\n",
        "            # Wrap server execution in a try-except block\n",
        "    try:\n",
        "        components = ServerAppComponents(strategy=strategy, config=config)\n",
        "        # Run some initial checks for configuration issues\n",
        "        print(\"Initial parameters shape:\", [p.shape for p in params])\n",
        "        print(\"Initial parameters type:\", [p.dtype for p in params])\n",
        "        return components\n",
        "    except Exception as e:\n",
        "        print(f\"Error during server initialization or execution: {e}\")\n",
        "        raise e  # Re-raise the exception for traceback\n",
        "    return ServerAppComponents(strategy=strategy, config=config)\n",
        "\n",
        "# Create the ServerApp\n",
        "server_app = ServerApp(server_fn=server_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TlAZPF6MW2sz"
      },
      "outputs": [],
      "source": [
        "# Specify the resources each of your clients need\n",
        "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
        "backend_config = {\"client_resources\": {\"num_cpus\": 2, \"num_gpus\": 1.0 }}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0qF2cJLW2s0"
      },
      "source": [
        "### 6.5. Run Flower SIMULATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OreWZkYW2s0"
      },
      "outputs": [],
      "source": [
        "# Start simulation\n",
        "run_simulation(\n",
        "    server_app=server_app,\n",
        "    client_app=client_app,\n",
        "    num_supernodes=NUM_CLIENTS,\n",
        "    backend_config=backend_config,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sowrDKDIOZ2g"
      },
      "outputs": [],
      "source": [
        "def plot_time_curve():\n",
        "\n",
        "    global round_times, aggregation_times\n",
        "\n",
        "    if not round_times:\n",
        "        print(\"No timing data collected during simulation.\")\n",
        "        return\n",
        "\n",
        "    # Extract rounds and times\n",
        "    rounds = [r for r, _ in round_times]\n",
        "    times = [t for _, t in round_times]\n",
        "    cumulative_times = np.cumsum(times)  # Compute cumulative time\n",
        "\n",
        "    # Plot the results\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(rounds, cumulative_times, marker='o', linestyle='-', color='b', label='Cumulative Time')\n",
        "    plt.xlabel('Number of Rounds')\n",
        "    plt.ylabel('Cumulative Time (seconds)')\n",
        "    plt.title('Cumulative Time Taken vs. Number of Rounds (Client Training and Aggregation)')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Display total time\n",
        "    print(round_times)\n",
        "    total_time = cumulative_times[-1]\n",
        "    print(f\"Total time taken for {len(rounds)} rounds (client training and aggregation): {total_time:.2f} seconds\")\n",
        "    avg_duration = sum(duration for _, duration in round_times) / len(round_times)\n",
        "    print(f\"Average round duration: {avg_duration:.2f} seconds\")\n",
        "    print(aggregation_times)\n",
        "    avg_aggregation_time = sum(duration for _, duration in aggregation_times) / len(aggregation_times)\n",
        "    print(f\"Average aggregation time: {avg_aggregation_time:.2f} seconds\")\n",
        "plot_time_curve()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}